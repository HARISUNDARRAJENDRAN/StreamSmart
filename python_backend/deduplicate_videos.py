#!/usr/bin/env python3
"""
Deduplicate Videos Script for StreamSmart
Removes duplicate videos and ensures unique keys throughout the dataset
"""

import asyncio
import logging
import sys
import os
from collections import defaultdict, Counter

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Add services directory to path
sys.path.append(os.path.join(os.path.dirname(__file__), 'services'))

async def deduplicate_videos():
    """Remove duplicate videos from MongoDB and ensure uniqueness"""
    
    print("üßπ StreamSmart Video Deduplication")
    print("=" * 50)
    
    try:
        from smart_recommendation_service import get_smart_recommendation_service
        
        service = await get_smart_recommendation_service()
        await service.initialize()
        
        print("üîç Analyzing video database for duplicates...")
        
        # Get all videos
        all_videos = []
        async for video in service.videos_collection.find({}):
            all_videos.append(video)
        
        print(f"üìä Total videos in database: {len(all_videos)}")
        
        # Analyze duplicates
        video_id_counts = Counter()
        video_id_to_docs = defaultdict(list)
        
        for video in all_videos:
            video_id = video.get('video_id', '')
            if video_id:
                video_id_counts[video_id] += 1
                video_id_to_docs[video_id].append(video)
        
        # Find duplicates
        duplicate_video_ids = [vid for vid, count in video_id_counts.items() if count > 1]
        
        print(f"üîç Found {len(duplicate_video_ids)} duplicate video IDs")
        
        if not duplicate_video_ids:
            print("‚úÖ No duplicates found! Database is clean.")
            await service.close()
            return
        
        # Show some examples
        print(f"\nüìã Sample Duplicates:")
        for i, vid in enumerate(duplicate_video_ids[:5], 1):
            count = video_id_counts[vid]
            titles = [doc.get('title', 'Untitled')[:50] for doc in video_id_to_docs[vid]]
            print(f"   {i}. {vid}: {count} copies")
            print(f"      Title: {titles[0]}...")
        
        if len(duplicate_video_ids) > 5:
            print(f"   ... and {len(duplicate_video_ids) - 5} more duplicates")
        
        # Remove duplicates
        print(f"\nüßπ Removing duplicates...")
        
        removed_count = 0
        kept_count = 0
        
        for video_id in duplicate_video_ids:
            docs = video_id_to_docs[video_id]
            
            # Keep the first one (usually has the most complete data)
            best_doc = docs[0]
            
            # Merge genres from all duplicates
            all_genres = set()
            for doc in docs:
                if 'genres' in doc:
                    all_genres.update(doc['genres'])
                elif 'genre' in doc:
                    all_genres.add(doc['genre'])
            
            # Update the best document with merged genres
            if all_genres:
                await service.videos_collection.update_one(
                    {'_id': best_doc['_id']},
                    {'$set': {'genres': list(all_genres)}}
                )
            
            # Remove all other duplicates
            for doc in docs[1:]:
                await service.videos_collection.delete_one({'_id': doc['_id']})
                removed_count += 1
            
            kept_count += 1
        
        print(f"‚úÖ Deduplication complete!")
        print(f"   Kept: {kept_count} unique videos")
        print(f"   Removed: {removed_count} duplicates")
        
        # Verify the cleanup
        final_count = await service.videos_collection.count_documents({})
        print(f"   Final database size: {final_count} videos")
        
        # Create updated statistics
        print(f"\nüìä Updated Database Statistics:")
        stats = await service.get_stats()
        
        if "error" not in stats:
            print(f"   Total Videos: {stats['total_videos']}")
            print(f"   Genres Available: {len(stats['genres'])}")
            
            print(f"\nüìà Genre Distribution (Top 10):")
            for genre_data in stats['genres'][:10]:
                genre_name = genre_data['genre'].replace('-', ' ').title()
                print(f"   {genre_name}: {genre_data['count']} videos")
        
        await service.close()
        
        print(f"\nüéâ Database Deduplication Complete!")
        print("=" * 50)
        
        return True
        
    except Exception as e:
        logger.error(f"Error during deduplication: {e}")
        print(f"‚ùå Deduplication failed: {str(e)}")
        return False

async def verify_uniqueness():
    """Verify that all video IDs are now unique"""
    
    print("\nüîç Verifying Video ID Uniqueness")
    print("-" * 40)
    
    try:
        from smart_recommendation_service import get_smart_recommendation_service
        
        service = await get_smart_recommendation_service()
        await service.initialize()
        
        # Check for duplicates
        pipeline = [
            {"$group": {"_id": "$video_id", "count": {"$sum": 1}}},
            {"$match": {"count": {"$gt": 1}}}
        ]
        
        duplicates = []
        async for result in service.videos_collection.aggregate(pipeline):
            duplicates.append(result)
        
        if duplicates:
            print(f"‚ùå Still found {len(duplicates)} duplicate video IDs:")
            for dup in duplicates[:5]:
                print(f"   {dup['_id']}: {dup['count']} copies")
        else:
            print("‚úÖ All video IDs are now unique!")
        
        await service.close()
        return len(duplicates) == 0
        
    except Exception as e:
        logger.error(f"Error during verification: {e}")
        return False

if __name__ == "__main__":
    print("üöÄ StreamSmart Database Deduplication Tool")
    
    # Run deduplication
    success = asyncio.run(deduplicate_videos())
    
    if success:
        # Verify uniqueness
        asyncio.run(verify_uniqueness())
        
        print("\nüí° Next Steps:")
        print("1. Restart your FastAPI backend")
        print("2. Test the frontend - no more duplicate key errors!")
        print("3. Each genre will return exactly 51 unique videos")
    
    print("\n‚úÖ Database is ready for production deployment!") 